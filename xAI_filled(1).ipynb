{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "magnetic-horizon",
   "metadata": {},
   "source": [
    "### LIME Implementation \n",
    "Sources:\n",
    "\n",
    "- Based on: https://towardsdatascience.com/lime-how-to-interpret-machine-learning-models-with-python-94b0e7e4432e\n",
    "\n",
    "- Github Repo for LIME: https://github.com/marcotcr/lime\n",
    "\n",
    "- dataset: https://www.kaggle.com/datasets/piyushagni5/white-wine-quality?resource=download\n",
    "\n",
    "> more resources on LIME:\n",
    "* https://homes.cs.washington.edu/~marcotcr/blog/lime/\n",
    "* https://subscription.packtpub.com/book/data/9781800208131/8/ch08lvl1sec64/getting-started-with-lime\n",
    "* https://towardsdatascience.com/top-5-techniques-for-explainable-ai-34349990cc83\n",
    "* https://www.thepythoncode.com/article/explainable-ai-model-python (ELI5) \n",
    "* https://towardsdatascience.com/essential-explainable-ai-python-frameworks-that-you-should-know-about-84d5063b75e9 (other frameworks)\n",
    "* https://christophm.github.io/interpretable-ml-book/ (really detailed - Book)\n",
    "* https://github.com/PacktPublishing/Hands-On-Explainable-AI-XAI-with-Python (Book) \n",
    "\n",
    "R tutorial: \n",
    "https://algoritmaonline.com/interpreting-classification-model-with-lime/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-contractor",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#install lime \n",
    "\n",
    "%pip install lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-beijing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports and reading data \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('winedata.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-prisoner",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-bidding",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-breast",
   "metadata": {},
   "source": [
    "### Task at hand: Classification of Wine Quality \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-physiology",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quality'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-telephone",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace with \"good\" and \"bad\" \n",
    "\n",
    "def replace_numeric(val):\n",
    "    if val <= 5:\n",
    "        val = 'bad'\n",
    "    else:\n",
    "        val = 'good'\n",
    "    \n",
    "    return val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-perry",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality = df['quality'].tolist()\n",
    "quality[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-officer",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-taste",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_qual = []\n",
    "for i in range(len(quality)):\n",
    "    cat_qual.insert(i, replace_numeric(quality[i]))\n",
    "    \n",
    "cat_qual[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-value",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_qual = pd.Series(cat_qual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-virgin",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cat_quality'] = ser_qual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-italy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scientific-chick",
   "metadata": {},
   "source": [
    "### training classifier: Random Forest \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-effects",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = df.drop(columns = ['quality', 'cat_quality'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-harvey",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['cat_quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-wagner",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-panama",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "RF = RandomForestClassifier(random_state = 42)\n",
    "RF_fit = RF.fit(x_train, y_train)\n",
    "RF_pred = RF.predict(x_test)\n",
    "\n",
    "score = RF_fit.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-camera",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "\n",
    "precision = precision_score(y_test, RF_pred, average = 'micro')\n",
    "print('Precision: %.3f' % precision)\n",
    "\n",
    "recall = recall_score(y_test, RF_pred, average = 'micro')\n",
    "print('Recall: %.3f' % recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-candle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns \n",
    "\n",
    "confMat = confusion_matrix(y_test, RF_pred)\n",
    "\n",
    "print(\" Confusion Matrix: \")\n",
    "print(\"-------------------\")\n",
    "  \n",
    "confMat_df = pd.DataFrame(confMat, columns = ['TP&FN', 'FP&TN'])\n",
    "print(confMat_df)\n",
    "print('====================')\n",
    "\n",
    "sns.heatmap(confMat/np.sum(confMat), annot=True, fmt='.2%') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-return",
   "metadata": {},
   "source": [
    "### Model Interpretation \n",
    "\n",
    "So far, we haven't done anything new. Now, we will import LIME and create a tabular explainer object. It requires 4 parameters: \n",
    "\n",
    "- training data: what are we training on \n",
    "- feature names: column names \n",
    "- class names: in this case, \"good\" and \"bad\" \n",
    "- model: the type of ML problem, in this case just a classification\n",
    "\n",
    "For lime tabular, source: \n",
    "https://lime-ml.readthedocs.io/en/latest/lime.html#module-lime.lime_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-purpose",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime \n",
    "from lime import lime_tabular \n",
    "\n",
    "explainer = lime_tabular.LimeTabularExplainer(\n",
    "    training_data = np.array(x_train),\n",
    "    feature_names = x_train.columns, \n",
    "    class_names = ['bad', 'good'],\n",
    "    mode = 'classification'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-reviewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-equity",
   "metadata": {},
   "source": [
    "Now, we create an instance of the explainanation. \n",
    "\n",
    "> \"explain_instance(data_row, predict_fn, labels=(1, ), top_labels=None, num_features=10, num_samples=5000, distance_metric='euclidean', model_regressor=None, sampling_method='gaussian')\n",
    "\n",
    "> Generates explanations for a prediction.\n",
    "\n",
    "> First, we generate neighborhood data by randomly perturbing features from the instance (see __data_inverse). We then learn locally weighted linear models on this neighborhood data to explain each of the classes in an interpretable way (see lime_base.py).\" \n",
    "\n",
    "Explaination: \n",
    "\n",
    "- data_row: a row of your data you want to use to explain the result of the prediction on \n",
    "- predict_fn: prediction function, in a classifier this outputs a probability (of belonging to a class). In regression, it is the actual predicted value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-sperm",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-packet",
   "metadata": {},
   "source": [
    "https://github.com/scikit-learn/scikit-learn/blob/9aaed4987/sklearn/ensemble/_forest.py#L838"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-leeds",
   "metadata": {},
   "source": [
    "Let's see a good wine and a bad wine: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-married",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "injured-evolution",
   "metadata": {},
   "source": [
    "Locations: 0, 1, 2 are \"good\" and 3 is \"bad\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-constitution",
   "metadata": {},
   "outputs": [],
   "source": [
    "#good wine\n",
    "exp = explainer.explain_instance(\n",
    "    data_row = x_test.iloc[1], \n",
    "    predict_fn = RF_fit.predict_proba\n",
    ")\n",
    "\n",
    "exp.show_in_notebook(show_table = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-yesterday",
   "metadata": {},
   "source": [
    "### Interpretation: \n",
    "\n",
    "#### Part 1. (Left) : Confidence \n",
    "- Model is 96% confident that this is a \"good\" wine. (We know it is) \n",
    "\n",
    "\n",
    "#### Part 2. (Middle) : Feature Importance \n",
    "- Things that matter in this classification: Alcohol level (19%), volatile acidity (10%), density (7%), and citric acid (5%)\n",
    "\n",
    "> When is a wine bad? \n",
    "- high levels of \"volatile acidity\" (greater than 0.33), it is 0.53 here \n",
    "- low levels of \"citric acid\" (lower than 0.27), it is 0.16 here\n",
    "\n",
    "> When is a wine good? \n",
    "- Alcohol greater than 11.40, it's 13.2 here \n",
    "- density lower than 0.99, it's 0.99 here \n",
    "- chlorides lower than 0.04, it is 0.04 here \n",
    "\n",
    "and so on \n",
    "\n",
    "#### Part 3. (Right) : Values \n",
    "Just to check. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-housing",
   "metadata": {},
   "source": [
    "### Class of \"BAD\" Example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-diploma",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp2 = explainer.explain_instance(\n",
    "    data_row = x_test.iloc[3],\n",
    "    predict_fn = RF_fit.predict_proba\n",
    ")\n",
    "\n",
    "exp2.show_in_notebook(show_table = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norman-testing",
   "metadata": {},
   "source": [
    "### Interpretation: \n",
    "\n",
    "#### Part 1. (Left) : Confidence \n",
    "- Model is 84% confident that this is a \"bad\" wine. (We know it is) \n",
    "\n",
    "\n",
    "#### Part 2. (Middle) : Feature Importance \n",
    "- Things that matter in this classification: Alcohol level (8%), residual sugar (6%), chlorides (5%)\n",
    "\n",
    "> When is a wine bad? \n",
    "- low levels of \"residual sugar\" (less than 1.7), it is 1.6 here \n",
    "- high levels of chlorides (greater than 0.05), it is 0.05 here\n",
    "\n",
    "> When is a wine good? \n",
    "- Alcohol between 10.4 and 11.40, it's 10.7 here \n",
    "\n",
    "\n",
    "#### Part 3. (Right) : Values \n",
    "Just to check. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-surveillance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
